{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words (BoW) Cheat Sheet\n",
    "\n",
    "### Definition\n",
    "- **Bag of Words** is a text representation technique in NLP that converts text data into numerical form for further analysis or model building.\n",
    "- It disregards grammar and word order but considers word frequency.\n",
    "\n",
    "### Steps to Create a Bag of Words\n",
    "1. **Text Preprocessing:**\n",
    "   - Convert all text to lowercase.\n",
    "   - Remove punctuation, numbers, and special characters.\n",
    "   - Perform stemming or lemmatization (optional).\n",
    "   - Remove stopwords (e.g., \"and\", \"the\", \"is\").\n",
    "\n",
    "2. **Tokenization:**\n",
    "   - Split the text into individual words or tokens.\n",
    "\n",
    "3. **Building Vocabulary:**\n",
    "   - Create a set of all unique words in the text.\n",
    "\n",
    "4. **Vectorization:**\n",
    "   - Create a vector of word frequencies (or binary presence/absence) for each document.\n",
    "\n",
    "5. **Creating the Matrix:**\n",
    "   - Represent each document as a row in a matrix where each column corresponds to a unique word from the vocabulary, and the value represents the frequency of the word in that document.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Advantages\n",
    "- **Simplicity:** Easy to implement and understand.\n",
    "- **Efficiency:** Works well for smaller, less complex texts.\n",
    "- **Sparse Representation:** Suitable for machine learning models as it represents the presence or frequency of words numerically.\n",
    "\n",
    "### Disadvantages\n",
    "- **Loss of Context:** Ignores the order of words and semantic meaning.\n",
    "- **High Dimensionality:** Can lead to very large feature spaces for extensive vocabularies, making it computationally expensive.\n",
    "- **Sensitivity to Stopwords:** Common words might dominate the representation, skewing results if not handled correctly.\n",
    "- **Difficulty with Semantic Similarity:** Does not capture meaning or relationships between words.\n",
    "\n",
    "### Use Cases\n",
    "- Text Classification\n",
    "- Sentiment Analysis\n",
    "- Information Retrieval\n",
    "\n",
    "### Common Variants\n",
    "- **TF-IDF (Term Frequency-Inverse Document Frequency):** Adjusts word frequency by considering how common or rare a word is across all documents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "### Problem Statement\n",
    "Convert a sample text dataset into a Bag of Words representation.\n",
    "\n",
    "#### Input Texts\n",
    "1. \"I love NLP and machine learning.\"\n",
    "2. \"NLP is great for text processing.\"\n",
    "3. \"I love learning new techniques in NLP.\"\n",
    "\n",
    "#### Step 1: Text Preprocessing\n",
    "1. Convert to lowercase.\n",
    "2. Remove punctuation and special characters.\n",
    "3. Remove stopwords (e.g., \"and\", \"is\", \"for\", etc.).\n",
    "\n",
    "#### Preprocessed Texts\n",
    "1. \"love nlp machine learning\"\n",
    "2. \"nlp great text processing\"\n",
    "3. \"love learning new techniques nlp\"\n",
    "\n",
    "#### Step 2: Tokenization\n",
    "- Tokenize the preprocessed texts into words.\n",
    "\n",
    "#### Step 3: Building Vocabulary\n",
    "- Vocabulary: {\"love\", \"nlp\", \"machine\", \"learning\", \"great\", \"text\", \"processing\", \"new\", \"techniques\"}\n",
    "\n",
    "#### Step 4: Vectorization\n",
    "- Create a word frequency vector for each text.\n",
    "\n",
    "#### Word Frequency Matrix\n",
    "| Text | love | nlp | machine | learning | great | text | processing | new | techniques |\n",
    "|------|------|-----|---------|----------|-------|------|------------|-----|------------|\n",
    "| 1    | 1    | 1   | 1       | 1        | 0     | 0    | 0          | 0   | 0          |\n",
    "| 2    | 0    | 1   | 0       | 0        | 1     | 1    | 1          | 0   | 0          |\n",
    "| 3    | 1    | 1   | 0       | 1        | 0     | 0    | 0          | 1   | 1          |\n",
    "\n",
    "#### Step 5: Creating the Matrix\n",
    "- Each document is represented as a row in the matrix, and each unique word is a column.\n",
    "- The value in each cell is the frequency of the word in that document.\n",
    "\n",
    "### Conclusion\n",
    "The resulting Bag of Words matrix effectively represents the frequency of words in each document, disregarding the order or grammar of words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FirstsVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
